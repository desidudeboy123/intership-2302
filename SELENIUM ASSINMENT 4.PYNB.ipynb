{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#       ASSINGMENT 4 PDF 4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.8.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuUES1...... Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.By import by\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Documents\\data trained.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element_by_xpath('//*[@id=\"noarticletext\"]/tbody/tr/td/span/a')       \n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_2 = driver.find_element_by_xpath('//*[@id=\"mw-content-text\"]/div[3]/ul/li[1]/div[1]/a')        \n",
    "search_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n"
     ]
    }
   ],
   "source": [
    "rk=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[1]\")\n",
    "for i in rk:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['\"Baby Shark Dance\"[28]', '\"Despacito\"[30]', '\"Shape of You\"[31]', '\"See You Again\"[32]', '\"Johny Johny Yes Papa\"[35]', '\"Masha and the Bear – Recipe for Disaster\"[36]', '\"Uptown Funk\"[37]', '\"Gangnam Style\"[38]', '\"Learning Colors – Colorful Eggs on a Farm\"[40]', '\"Bath Song\"[41]', '\"Phonics Song with Two Words\"[42]', '\"Sorry\"[43]', '\"Sugar\"[44]', '\"Roar\"[45]', '\"Counting Stars\"[46]', '\"Thinking Out Loud\"[47]', '\"Dame Tu Cosita\"[48]', '\"Shake It Off\"[49]', '\"Faded\"[50]', '\"Lean On\"[51]', '\"Bailando\"[52]', '\"Dark Horse\"[53]', '\"Girls Like You\"[54]', '\"Let Her Go\"[55]', '\"Mi Gente\"[56]', '\"Hello\"[57]', '\"Perfect\"[58]', '\"Waka Waka (This Time for Africa)\"[59]', '\"Blank Space\"[60]', '\"Chantaje\"[61]']\n"
     ]
    }
   ],
   "source": [
    "nm=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[2]\")\n",
    "for i in nm:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [\"Pinkfong Kids' Songs & Stories\", 'Luis Fonsi featuring Daddy Yankee', 'Ed Sheeran', 'Wiz Khalifa featuring Charlie Puth', 'LooLoo Kids', 'Get Movies', 'Mark Ronson featuring Bruno Mars', 'Psy', 'Miroshka TV', 'Cocomelon – Nursery Rhymes', 'ChuChu TV', 'Justin Bieber', 'Maroon 5', 'Katy Perry', 'OneRepublic', 'Ed Sheeran', 'El Chombo featuring Cutty Ranks', 'Taylor Swift', 'Alan Walker', 'Major Lazer and DJ Snake featuring MØ', 'Enrique Iglesias featuring Descemer Bueno and Gente De Zona', 'Katy Perry featuring Juicy J', 'Maroon 5 featuring Cardi B', 'Passenger', 'J Balvin and Willy William', 'Adele', 'Ed Sheeran', 'Shakira featuring Freshlyground', 'Taylor Swift', 'Shakira featuring Maluma']\n"
     ]
    }
   ],
   "source": [
    "Ar=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[3]\")\n",
    "for i in Ar:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)\n",
    "print(len(Artist),Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['June 17, 2016', 'January 12, 2017', 'January 30, 2017', 'April 6, 2015', 'October 8, 2016', 'January 31, 2012', 'November 19, 2014', 'July 15, 2012', 'February 27, 2018', 'May 2, 2018', 'March 6, 2014', 'October 22, 2015', 'January 14, 2015', 'September 5, 2013', 'May 31, 2013', 'October 7, 2014', 'April 5, 2018', 'August 18, 2014', 'December 3, 2015', 'March 22, 2015', 'April 11, 2014', 'February 20, 2014', 'May 31, 2018', 'July 25, 2012', 'June 29, 2017', 'October 22, 2015', 'November 9, 2017', 'June 4, 2010', 'November 10, 2014', 'November 18, 2016']\n"
     ]
    }
   ],
   "source": [
    " date=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[5]\")\n",
    "for i in date:\n",
    "    if i.text is None :\n",
    "        Upload_Date.append(\"--\") \n",
    "    else:\n",
    "        Upload_Date.append(i.text)\n",
    "print(len(Upload_Date),Upload_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 ['7.91', '7.20', '5.18', '4.96', '4.77', '4.41', '4.09', '3.97', '3.69', '3.64', '3.53', '3.40', '3.39', '3.27', '3.19', '3.18', '3.11', '3.02', '2.98', '2.97', '2.97', '2.97', '2.96', '2.91', '2.86', '2.79', '2.74', '2.74', '2.72', '2.62']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Views \n",
    "v=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[4]\")\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Views.append(\"--\") \n",
    "    else:\n",
    "        Views.append(i.text)\n",
    "print(len(Views),Views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views In Bllion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[28]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[30]</td>\n",
       "      <td>Luis Fonsi featuring Daddy Yankee</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Shape of You\"[31]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"See You Again\"[32]</td>\n",
       "      <td>Wiz Khalifa featuring Charlie Puth</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[35]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[37]</td>\n",
       "      <td>Mark Ronson featuring Bruno Mars</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Gangnam Style\"[38]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[40]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Bath Song\"[41]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[42]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sugar\"[44]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Roar\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Counting Stars\"[46]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Thinking Out Loud\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Dame Tu Cosita\"[48]</td>\n",
       "      <td>El Chombo featuring Cutty Ranks</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Shake It Off\"[49]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[50]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lean On\"[51]</td>\n",
       "      <td>Major Lazer and DJ Snake featuring MØ</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias featuring Descemer Bueno and ...</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[53]</td>\n",
       "      <td>Katy Perry featuring Juicy J</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5 featuring Cardi B</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[55]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Mi Gente\"[56]</td>\n",
       "      <td>J Balvin and Willy William</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Hello\"[57]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[58]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[59]</td>\n",
       "      <td>Shakira featuring Freshlyground</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Blank Space\"[60]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>November 10, 2014</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Chantaje\"[61]</td>\n",
       "      <td>Shakira featuring Maluma</td>\n",
       "      <td>November 18, 2016</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                      Video Title  \\\n",
       "0    1.                           \"Baby Shark Dance\"[28]   \n",
       "1    2.                                  \"Despacito\"[30]   \n",
       "2    3.                               \"Shape of You\"[31]   \n",
       "3    4.                              \"See You Again\"[32]   \n",
       "4    5.                       \"Johny Johny Yes Papa\"[35]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "6    7.                                \"Uptown Funk\"[37]   \n",
       "7    8.                              \"Gangnam Style\"[38]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[40]   \n",
       "9   10.                                  \"Bath Song\"[41]   \n",
       "10  11.                \"Phonics Song with Two Words\"[42]   \n",
       "11  12.                                      \"Sorry\"[43]   \n",
       "12  13.                                      \"Sugar\"[44]   \n",
       "13  14.                                       \"Roar\"[45]   \n",
       "14  15.                             \"Counting Stars\"[46]   \n",
       "15  16.                          \"Thinking Out Loud\"[47]   \n",
       "16  17.                             \"Dame Tu Cosita\"[48]   \n",
       "17  18.                               \"Shake It Off\"[49]   \n",
       "18  19.                                      \"Faded\"[50]   \n",
       "19  20.                                    \"Lean On\"[51]   \n",
       "20  21.                                   \"Bailando\"[52]   \n",
       "21  22.                                 \"Dark Horse\"[53]   \n",
       "22  23.                             \"Girls Like You\"[54]   \n",
       "23  24.                                 \"Let Her Go\"[55]   \n",
       "24  25.                                   \"Mi Gente\"[56]   \n",
       "25  26.                                      \"Hello\"[57]   \n",
       "26  27.                                    \"Perfect\"[58]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[59]   \n",
       "28  29.                                \"Blank Space\"[60]   \n",
       "29  30.                                   \"Chantaje\"[61]   \n",
       "\n",
       "                                               Artist        Upload_Date  \\\n",
       "0                      Pinkfong Kids' Songs & Stories      June 17, 2016   \n",
       "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017   \n",
       "2                                          Ed Sheeran   January 30, 2017   \n",
       "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015   \n",
       "4                                         LooLoo Kids    October 8, 2016   \n",
       "5                                          Get Movies   January 31, 2012   \n",
       "6                    Mark Ronson featuring Bruno Mars  November 19, 2014   \n",
       "7                                                 Psy      July 15, 2012   \n",
       "8                                         Miroshka TV  February 27, 2018   \n",
       "9                          Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "10                                          ChuChu TV      March 6, 2014   \n",
       "11                                      Justin Bieber   October 22, 2015   \n",
       "12                                           Maroon 5   January 14, 2015   \n",
       "13                                         Katy Perry  September 5, 2013   \n",
       "14                                        OneRepublic       May 31, 2013   \n",
       "15                                         Ed Sheeran    October 7, 2014   \n",
       "16                    El Chombo featuring Cutty Ranks      April 5, 2018   \n",
       "17                                       Taylor Swift    August 18, 2014   \n",
       "18                                        Alan Walker   December 3, 2015   \n",
       "19              Major Lazer and DJ Snake featuring MØ     March 22, 2015   \n",
       "20  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014   \n",
       "21                       Katy Perry featuring Juicy J  February 20, 2014   \n",
       "22                         Maroon 5 featuring Cardi B       May 31, 2018   \n",
       "23                                          Passenger      July 25, 2012   \n",
       "24                         J Balvin and Willy William      June 29, 2017   \n",
       "25                                              Adele   October 22, 2015   \n",
       "26                                         Ed Sheeran   November 9, 2017   \n",
       "27                    Shakira featuring Freshlyground       June 4, 2010   \n",
       "28                                       Taylor Swift  November 10, 2014   \n",
       "29                           Shakira featuring Maluma  November 18, 2016   \n",
       "\n",
       "   Views In Bllion  \n",
       "0             7.91  \n",
       "1             7.20  \n",
       "2             5.18  \n",
       "3             4.96  \n",
       "4             4.77  \n",
       "5             4.41  \n",
       "6             4.09  \n",
       "7             3.97  \n",
       "8             3.69  \n",
       "9             3.64  \n",
       "10            3.53  \n",
       "11            3.40  \n",
       "12            3.39  \n",
       "13            3.27  \n",
       "14            3.19  \n",
       "15            3.18  \n",
       "16            3.11  \n",
       "17            3.02  \n",
       "18            2.98  \n",
       "19            2.97  \n",
       "20            2.97  \n",
       "21            2.97  \n",
       "22            2.96  \n",
       "23            2.91  \n",
       "24            2.86  \n",
       "25            2.79  \n",
       "26            2.74  \n",
       "27            2.74  \n",
       "28            2.72  \n",
       "29            2.62  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube_Video=pd.DataFrame([])\n",
    "Youtube_Video['Rank']=Rank\n",
    "Youtube_Video['Video Title']=Name\n",
    "Youtube_Video['Artist']=Artist\n",
    "Youtube_Video['Upload_Date']=Upload_Date\n",
    "Youtube_Video['Views In Bllion']=Views\n",
    "Youtube_Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****QUES2..... Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2=\"https://www.bcci.tv/international/fixtures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team=[]\n",
    "Date_Time =[]\n",
    "Ground=[]\n",
    "Test_ODI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['INDIA\\nENGLAND\\nLIVE', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'INDIA\\nENGLAND', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA', 'ENGLAND\\nINDIA']\n"
     ]
    }
   ],
   "source": [
    "tm=driver.find_elements_by_xpath(\"//div[@class='fixture__teams']\")\n",
    "for i in tm:\n",
    "    if i.text is None :\n",
    "        Team.append(\"--\") \n",
    "    else:\n",
    "        Team.append(i.text)\n",
    "print(len(Team),Team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['Saturday 13 February 09:30 IST', 'Wednesday 24 February 14:30 IST', 'Thursday 4 March 09:30 IST', 'Friday 12 March 19:00 IST', 'Sunday 14 March 19:00 IST', 'Tuesday 16 March 19:00 IST', 'Thursday 18 March 19:00 IST', 'Saturday 20 March 19:00 IST', 'Tuesday 23 March 13:30 IST', 'Friday 26 March 13:30 IST', 'Sunday 28 March 13:30 IST', 'Wednesday 4 August 15:30 IST', 'Thursday 12 August 15:30 IST', 'Wednesday 25 August 15:30 IST', 'Thursday 2 September 15:30 IST', 'Friday 10 September 15:30 IST']\n"
     ]
    }
   ],
   "source": [
    "DT=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']\")\n",
    "for i in DT:\n",
    "    if i.text is None :\n",
    "        Date_Time.append(\"--\") \n",
    "    else:\n",
    "        Date_Time.append(i.text)\n",
    "print(len(Date_Time),Date_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['M. A. Chidambaram Stadium, Chennai', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Sardar Patel Stadium, Ahmedabad', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Trent Bridge, Nottingham', \"Lord's, London\", 'Headingley, Leeds', 'The Oval, London', 'Old Trafford, Manchester']\n"
     ]
    }
   ],
   "source": [
    "G=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in G:\n",
    "    if i.text is None :\n",
    "        Ground.append(\"--\") \n",
    "    else:\n",
    "        Ground.append(i.text)\n",
    "print(len(Ground),Ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ['2nd Test', '3rd Test', '4th Test', '1st T20I', '2nd T20I', '3rd T20I', '4th T20I', '5th T20I', '1st ODI', '2nd ODI', '3rd ODI', '1st Test', '2nd Test', '3rd Test', '4th Test', '5th Test']\n"
     ]
    }
   ],
   "source": [
    "TO=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/strong\")\n",
    "for i in TO:\n",
    "    if i.text is None :\n",
    "        Test_ODI.append(\"--\") \n",
    "    else:\n",
    "        Test_ODI.append(i.text)\n",
    "print(len(Test_ODI),Test_ODI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA\\nENGLAND\\nLIVE</td>\n",
       "      <td>Saturday 13 February 09:30 IST</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>M. A. Chidambaram Stadium, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Wednesday 24 February 14:30 IST</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Thursday 4 March 09:30 IST</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Friday 12 March 19:00 IST</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Sunday 14 March 19:00 IST</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Tuesday 16 March 19:00 IST</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Thursday 18 March 19:00 IST</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Saturday 20 March 19:00 IST</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Tuesday 23 March 13:30 IST</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Friday 26 March 13:30 IST</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INDIA\\nENGLAND</td>\n",
       "      <td>Sunday 28 March 13:30 IST</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Wednesday 4 August 15:30 IST</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Thursday 12 August 15:30 IST</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Wednesday 25 August 15:30 IST</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Thursday 2 September 15:30 IST</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENGLAND\\nINDIA</td>\n",
       "      <td>Friday 10 September 15:30 IST</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Team                        Date_Time    Series  \\\n",
       "0   INDIA\\nENGLAND\\nLIVE   Saturday 13 February 09:30 IST  2nd Test   \n",
       "1         INDIA\\nENGLAND  Wednesday 24 February 14:30 IST  3rd Test   \n",
       "2         INDIA\\nENGLAND       Thursday 4 March 09:30 IST  4th Test   \n",
       "3         INDIA\\nENGLAND        Friday 12 March 19:00 IST  1st T20I   \n",
       "4         INDIA\\nENGLAND        Sunday 14 March 19:00 IST  2nd T20I   \n",
       "5         INDIA\\nENGLAND       Tuesday 16 March 19:00 IST  3rd T20I   \n",
       "6         INDIA\\nENGLAND      Thursday 18 March 19:00 IST  4th T20I   \n",
       "7         INDIA\\nENGLAND      Saturday 20 March 19:00 IST  5th T20I   \n",
       "8         INDIA\\nENGLAND       Tuesday 23 March 13:30 IST   1st ODI   \n",
       "9         INDIA\\nENGLAND        Friday 26 March 13:30 IST   2nd ODI   \n",
       "10        INDIA\\nENGLAND        Sunday 28 March 13:30 IST   3rd ODI   \n",
       "11        ENGLAND\\nINDIA     Wednesday 4 August 15:30 IST  1st Test   \n",
       "12        ENGLAND\\nINDIA     Thursday 12 August 15:30 IST  2nd Test   \n",
       "13        ENGLAND\\nINDIA    Wednesday 25 August 15:30 IST  3rd Test   \n",
       "14        ENGLAND\\nINDIA   Thursday 2 September 15:30 IST  4th Test   \n",
       "15        ENGLAND\\nINDIA    Friday 10 September 15:30 IST  5th Test   \n",
       "\n",
       "                                           Ground  \n",
       "0              M. A. Chidambaram Stadium, Chennai  \n",
       "1                 Sardar Patel Stadium, Ahmedabad  \n",
       "2                 Sardar Patel Stadium, Ahmedabad  \n",
       "3                 Sardar Patel Stadium, Ahmedabad  \n",
       "4                 Sardar Patel Stadium, Ahmedabad  \n",
       "5                 Sardar Patel Stadium, Ahmedabad  \n",
       "6                 Sardar Patel Stadium, Ahmedabad  \n",
       "7                 Sardar Patel Stadium, Ahmedabad  \n",
       "8   Maharashtra Cricket Association Stadium, Pune  \n",
       "9   Maharashtra Cricket Association Stadium, Pune  \n",
       "10  Maharashtra Cricket Association Stadium, Pune  \n",
       "11                       Trent Bridge, Nottingham  \n",
       "12                                 Lord's, London  \n",
       "13                              Headingley, Leeds  \n",
       "14                               The Oval, London  \n",
       "15                       Old Trafford, Manchester  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "International_Fixtures=pd.DataFrame([])\n",
    "International_Fixtures['Team']=Team\n",
    "International_Fixtures['Date_Time']=Date_Time\n",
    "International_Fixtures['Series']=Test_ODI\n",
    "International_Fixtures['Ground']=Ground\n",
    "International_Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***QUES3..... Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4=\"http://statisticstimes.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State =[]\n",
    "GDP=[]\n",
    "GSDP_Current=[]\n",
    "GSDP_Previous=[]\n",
    "Share=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/button')       \n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')       \n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')       \n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "r=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['Maharashtra', 'Uttar Pradesh', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Uttar Pradesh', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Telangana', 'Andhra Pradesh', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Jharkhand', 'Chhattisgarh', 'Uttarakhand', 'Himachal Pradesh', 'Jammu & Kashmir', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Sikkim', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "St=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['398.145', '252.278', '246.529', '233.552', '227.276', '164.820', '142.543', '130.501', '130.210', '122.431', '118.206', '117.180', '111.024', '80.204', '79.601', '74.437', '47.769', '45.982', '44.945', '37.186', '23.584', '23.265', '11.065', '7.538', '6.369', '5.543', '5.063', '4.344', '4.214', '4.126', '3.721', '2.952', '-']\n"
     ]
    }
   ],
   "source": [
    "gdp=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "print(len(GDP),GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['13.88%', '8.79%', '8.59%', '8.14%', '7.92%', '5.75%', '4.97%', '4.55%', '4.54%', '4.27%', '4.12%', '4.08%', '3.87%', '2.80%', '2.77%', '2.59%', '1.67%', '1.60%', '1.57%', '1.30%', '0.82%', '0.81%', '0.39%', '0.26%', '0.22%', '0.19%', '0.18%', '0.15%', '0.15%', '0.14%', '0.13%', '0.10%', '-']\n"
     ]
    }
   ],
   "source": [
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "print(len(Share),Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,632,792', '1,668,229', '1,630,208', '1,544,399', '1,502,899', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '492,229', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '36,656', '33,481', '28,723', '27,869', '27,283', '24,603', '19,520', '-']\n"
     ]
    }
   ],
   "source": [
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Current.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Current.append(i.text)\n",
    "print(len(GSDP_Current),GSDP_Current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 ['2,039,074', '1,137,469', '1,215,307', '1,124,423', '1,186,379', '739,525', '677,428', '621,301', '612,828', '522,009', '559,412', '590,569', '531,085', '375,651', '397,669', '382,218', '234,048', '231,182', '224,986', '193,273', '112,755', '117,851', '62,539', '36,963', '31,192', '24,442', '24,682', '18,722', '19,300', '17,647', '16,676', '14,524', '-']\n"
     ]
    }
   ],
   "source": [
    "shr=driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[8]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP_Previous.append(\"--\") \n",
    "    else:\n",
    "        GSDP_Previous.append(i.text)\n",
    "print(len(GSDP_Previous),GSDP_Previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share In GDP</th>\n",
       "      <th>GDP of State</th>\n",
       "      <th>GSDP_Current</th>\n",
       "      <th>GSDP_Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>398.145</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>8.79%</td>\n",
       "      <td>252.278</td>\n",
       "      <td>1,668,229</td>\n",
       "      <td>1,137,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.59%</td>\n",
       "      <td>246.529</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>233.552</td>\n",
       "      <td>1,544,399</td>\n",
       "      <td>1,124,423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>7.92%</td>\n",
       "      <td>227.276</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>5.75%</td>\n",
       "      <td>164.820</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>4.97%</td>\n",
       "      <td>142.543</td>\n",
       "      <td>942,586</td>\n",
       "      <td>677,428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>130.501</td>\n",
       "      <td>862,957</td>\n",
       "      <td>621,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>4.54%</td>\n",
       "      <td>130.210</td>\n",
       "      <td>861,031</td>\n",
       "      <td>612,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>4.27%</td>\n",
       "      <td>122.431</td>\n",
       "      <td>809,592</td>\n",
       "      <td>522,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4.12%</td>\n",
       "      <td>118.206</td>\n",
       "      <td>781,653</td>\n",
       "      <td>559,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>4.08%</td>\n",
       "      <td>117.180</td>\n",
       "      <td>774,870</td>\n",
       "      <td>590,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>111.024</td>\n",
       "      <td>734,163</td>\n",
       "      <td>531,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>80.204</td>\n",
       "      <td>530,363</td>\n",
       "      <td>375,651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>79.601</td>\n",
       "      <td>526,376</td>\n",
       "      <td>397,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2.59%</td>\n",
       "      <td>74.437</td>\n",
       "      <td>492,229</td>\n",
       "      <td>382,218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.769</td>\n",
       "      <td>315,881</td>\n",
       "      <td>234,048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>45.982</td>\n",
       "      <td>304,063</td>\n",
       "      <td>231,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>44.945</td>\n",
       "      <td>297,204</td>\n",
       "      <td>224,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.186</td>\n",
       "      <td>245,895</td>\n",
       "      <td>193,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>23.584</td>\n",
       "      <td>155,956</td>\n",
       "      <td>112,755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.265</td>\n",
       "      <td>153,845</td>\n",
       "      <td>117,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.065</td>\n",
       "      <td>73,170</td>\n",
       "      <td>62,539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.538</td>\n",
       "      <td>49,845</td>\n",
       "      <td>36,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.369</td>\n",
       "      <td>42,114</td>\n",
       "      <td>31,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.543</td>\n",
       "      <td>36,656</td>\n",
       "      <td>24,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.063</td>\n",
       "      <td>33,481</td>\n",
       "      <td>24,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.344</td>\n",
       "      <td>28,723</td>\n",
       "      <td>18,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.214</td>\n",
       "      <td>27,869</td>\n",
       "      <td>19,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.126</td>\n",
       "      <td>27,283</td>\n",
       "      <td>17,647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.721</td>\n",
       "      <td>24,603</td>\n",
       "      <td>16,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>0.10%</td>\n",
       "      <td>2.952</td>\n",
       "      <td>19,520</td>\n",
       "      <td>14,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Share In GDP GDP of State GSDP_Current  \\\n",
       "0     1                Maharashtra       13.88%      398.145    2,632,792   \n",
       "1     2              Uttar Pradesh        8.79%      252.278    1,668,229   \n",
       "2     3                 Tamil Nadu        8.59%      246.529    1,630,208   \n",
       "3     4                  Karnataka        8.14%      233.552    1,544,399   \n",
       "4     5                    Gujarat        7.92%      227.276    1,502,899   \n",
       "5     6                West Bengal        5.75%      164.820    1,089,898   \n",
       "6     7                  Rajasthan        4.97%      142.543      942,586   \n",
       "7     8             Andhra Pradesh        4.55%      130.501      862,957   \n",
       "8     9                  Telangana        4.54%      130.210      861,031   \n",
       "9    10             Madhya Pradesh        4.27%      122.431      809,592   \n",
       "10   11                     Kerala        4.12%      118.206      781,653   \n",
       "11   12                      Delhi        4.08%      117.180      774,870   \n",
       "12   13                    Haryana        3.87%      111.024      734,163   \n",
       "13   14                      Bihar        2.80%       80.204      530,363   \n",
       "14   15                     Punjab        2.77%       79.601      526,376   \n",
       "15   16                     Odisha        2.59%       74.437      492,229   \n",
       "16   17                      Assam        1.67%       47.769      315,881   \n",
       "17   18               Chhattisgarh        1.60%       45.982      304,063   \n",
       "18   19                  Jharkhand        1.57%       44.945      297,204   \n",
       "19   20                Uttarakhand        1.30%       37.186      245,895   \n",
       "20   21            Jammu & Kashmir        0.82%       23.584      155,956   \n",
       "21   22           Himachal Pradesh        0.81%       23.265      153,845   \n",
       "22   23                        Goa        0.39%       11.065       73,170   \n",
       "23   24                    Tripura        0.26%        7.538       49,845   \n",
       "24   25                 Chandigarh        0.22%        6.369       42,114   \n",
       "25   26                 Puducherry        0.19%        5.543       36,656   \n",
       "26   27                  Meghalaya        0.18%        5.063       33,481   \n",
       "27   28                     Sikkim        0.15%        4.344       28,723   \n",
       "28   29                    Manipur        0.15%        4.214       27,869   \n",
       "29   30                   Nagaland        0.14%        4.126       27,283   \n",
       "30   31          Arunachal Pradesh        0.13%        3.721       24,603   \n",
       "31   32                    Mizoram        0.10%        2.952       19,520   \n",
       "32   33  Andaman & Nicobar Islands            -            -            -   \n",
       "\n",
       "   GSDP_Previous  \n",
       "0      2,039,074  \n",
       "1      1,137,469  \n",
       "2      1,215,307  \n",
       "3      1,124,423  \n",
       "4      1,186,379  \n",
       "5        739,525  \n",
       "6        677,428  \n",
       "7        621,301  \n",
       "8        612,828  \n",
       "9        522,009  \n",
       "10       559,412  \n",
       "11       590,569  \n",
       "12       531,085  \n",
       "13       375,651  \n",
       "14       397,669  \n",
       "15       382,218  \n",
       "16       234,048  \n",
       "17       231,182  \n",
       "18       224,986  \n",
       "19       193,273  \n",
       "20       112,755  \n",
       "21       117,851  \n",
       "22        62,539  \n",
       "23        36,963  \n",
       "24        31,192  \n",
       "25        24,442  \n",
       "26        24,682  \n",
       "27        18,722  \n",
       "28        19,300  \n",
       "29        17,647  \n",
       "30        16,676  \n",
       "31        14,524  \n",
       "32             -  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_GDP=pd.DataFrame([])\n",
    "State_GDP['Rank']=Rank[0:33]\n",
    "State_GDP['State']=State[0:33]\n",
    "State_GDP['Share In GDP']=Share[0:33]\n",
    "State_GDP['GDP of State']=GDP[0:33]\n",
    "State_GDP['GSDP_Current']=GSDP_Current[0:33]\n",
    "State_GDP['GSDP_Previous']=GSDP_Previous[0:33]\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *****QUES4.. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5=\"https://github.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_Name =[]\n",
    "Language=[]\n",
    "Muted_Link=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details')       \n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]')       \n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['libsdl-org /', 'Azure /', 'system76 /', 'benbjohnson /', 'mbround18 /', 'deepmind /', 'satwikkansal /', 'vlang /', 'serhii-londar /', 'PowerShell /', 'ossu /', 'iptv-org /', 'streamich /', 'Azure /', 'adityatelange /', 'reactend /', 'flybywiresim /', 'Dimbreath /', 'hashicorp /', 'abhishekkrthakur /', 'florisboard /', 'goreleaser /', 'donnemartin /', 'dotnet /', 'reed-hong /']\n"
     ]
    }
   ],
   "source": [
    "RN=driver.find_elements_by_xpath(\"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['Simple Directmedia Layer', 'Azure Quickstart Templates', 'System76 Launch Configurable Keyboard', 'Streaming S3 replication for SQLite.', 'Valheim Docker server with Odin the CLI tool.', 'This repository contains implementations and illustrative code to accompany DeepMind publications', 'What the f*ck Python?', 'Simple, fast, safe, compiled language for developing maintainable software. Compiles itself in <1s with zero library dependencies. https://vlang.io', '🚀 Awesome list of open source applications for macOS. https://t.me/opensourcemacosapps', 'PowerShell for every system!', '🎓 Path to a free self-taught education in Computer Science!', 'Collection of 5000+ publicly available IPTV channels from all over the world', 'React Hooks — 👍', 'The source for REST API specifications for Microsoft Azure.', 'A fast, clean, responsive Hugo theme', 'React renderer to build Node.js server', 'The A32NX Project is a community driven open source project to create a free Airbus A320neo in Microsoft Flight Simulator that is as close to reality as possible. It aims to enhance the default A320neo by improving the systems depth and functionality to bring it up to payware-level, all for free.', 'Repository containing the game data for the game Genshin Impact.', 'A tool for secrets management, encryption as a service, and privileged access management', 'Run VSCode (codeserver) on Google Colab or Kaggle Notebooks', 'An open-source keyboard for Android. Currently in alpha/early-beta stage.', 'Deliver Go binaries as fast and easily as possible', 'Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.', 'ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.', 'A Curated List of Awesome Facebook Libra Resources']\n"
     ]
    }
   ],
   "source": [
    "Description=[]\n",
    "des=driver.find_elements_by_xpath(\"//p[@class='col-9 text-gray my-1 pr-4']\")\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ['C', 'PowerShell', 'Shell', 'Go', 'Rust', 'Jupyter Notebook', 'Python', 'V', 'Swift', 'C#', 'JavaScript', 'TypeScript', 'TypeScript', 'HTML', 'JavaScript', 'JavaScript', 'Go', 'Python', 'Kotlin', 'Go', 'Python', 'C#']\n"
     ]
    }
   ],
   "source": [
    "L=driver.find_elements_by_xpath(\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language.append(\"NAN\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "print(len(Language),Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['420', '22', '9,416', '12,234', '737', '14', '1,922', '32', '70', '12', '5,055', '978', '24,436', '2,095', '22,167', '1,326', '24,625', '1,648', '24,249', '3,923', '74,976', '10,823', '27,557', '861', '19,578', '1,373', '1,052', '2,649', '507', '230', '162', '8', '2,949', '466', '69', '20', '20,024', '2,793', '1,047', '144', '534', '48', '7,013', '503', '120,892', '22,004', '21,023', '6,006', '3,669', '167']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ml=driver.find_elements_by_xpath(\"//a[@class='muted-link d-inline-block mr-3']\")\n",
    "for i in ml:\n",
    "    if i.text is None :\n",
    "        Muted_Link.append(\"NAN\") \n",
    "    else:\n",
    "        Muted_Link.append(i.text)\n",
    "print(len(Muted_Link),Muted_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['22', '12,234', '14', '32', '12', '978', '2,095', '1,326', '1,648', '3,923', '10,823', '861', '1,373', '2,649', '230', '8', '466', '20', '2,793', '144', '48', '503', '22,004', '6,006', '167']\n"
     ]
    }
   ],
   "source": [
    "Muted=[]\n",
    "for i in range(1,len(Muted_Link),2):\n",
    "    Muted.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted),Muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['420', '9,416', '737', '1,922', '70', '5,055', '24,436', '22,167', '24,625', '24,249', '74,976', '27,557', '19,578', '1,052', '507', '162', '2,949', '69', '20,024', '1,047', '534', '7,013', '120,892', '21,023', '3,669']\n"
     ]
    }
   ],
   "source": [
    "Muted_Star=[]\n",
    "for i in range(0,len(Muted_Link),2):\n",
    "    Muted_Star.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted_Star),Muted_Star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Conutrybuted</th>\n",
       "      <th>Muted_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>libsdl-org /</td>\n",
       "      <td>Simple Directmedia Layer</td>\n",
       "      <td>C</td>\n",
       "      <td>22</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure /</td>\n",
       "      <td>Azure Quickstart Templates</td>\n",
       "      <td>PowerShell</td>\n",
       "      <td>12,234</td>\n",
       "      <td>9,416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system76 /</td>\n",
       "      <td>System76 Launch Configurable Keyboard</td>\n",
       "      <td>Shell</td>\n",
       "      <td>14</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benbjohnson /</td>\n",
       "      <td>Streaming S3 replication for SQLite.</td>\n",
       "      <td>Go</td>\n",
       "      <td>32</td>\n",
       "      <td>1,922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mbround18 /</td>\n",
       "      <td>Valheim Docker server with Odin the CLI tool.</td>\n",
       "      <td>Rust</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepmind /</td>\n",
       "      <td>This repository contains implementations and i...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>978</td>\n",
       "      <td>5,055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>satwikkansal /</td>\n",
       "      <td>What the f*ck Python?</td>\n",
       "      <td>Python</td>\n",
       "      <td>2,095</td>\n",
       "      <td>24,436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vlang /</td>\n",
       "      <td>Simple, fast, safe, compiled language for deve...</td>\n",
       "      <td>V</td>\n",
       "      <td>1,326</td>\n",
       "      <td>22,167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>serhii-londar /</td>\n",
       "      <td>🚀 Awesome list of open source applications for...</td>\n",
       "      <td>Swift</td>\n",
       "      <td>1,648</td>\n",
       "      <td>24,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>C#</td>\n",
       "      <td>3,923</td>\n",
       "      <td>24,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ossu /</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>10,823</td>\n",
       "      <td>74,976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iptv-org /</td>\n",
       "      <td>Collection of 5000+ publicly available IPTV ch...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>861</td>\n",
       "      <td>27,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>streamich /</td>\n",
       "      <td>React Hooks — 👍</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1,373</td>\n",
       "      <td>19,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Azure /</td>\n",
       "      <td>The source for REST API specifications for Mic...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>2,649</td>\n",
       "      <td>1,052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adityatelange /</td>\n",
       "      <td>A fast, clean, responsive Hugo theme</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>230</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reactend /</td>\n",
       "      <td>React renderer to build Node.js server</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flybywiresim /</td>\n",
       "      <td>The A32NX Project is a community driven open s...</td>\n",
       "      <td>Go</td>\n",
       "      <td>466</td>\n",
       "      <td>2,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dimbreath /</td>\n",
       "      <td>Repository containing the game data for the ga...</td>\n",
       "      <td>Python</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hashicorp /</td>\n",
       "      <td>A tool for secrets management, encryption as a...</td>\n",
       "      <td>Kotlin</td>\n",
       "      <td>2,793</td>\n",
       "      <td>20,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abhishekkrthakur /</td>\n",
       "      <td>Run VSCode (codeserver) on Google Colab or Kag...</td>\n",
       "      <td>Go</td>\n",
       "      <td>144</td>\n",
       "      <td>1,047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>florisboard /</td>\n",
       "      <td>An open-source keyboard for Android. Currently...</td>\n",
       "      <td>Python</td>\n",
       "      <td>48</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>goreleaser /</td>\n",
       "      <td>Deliver Go binaries as fast and easily as poss...</td>\n",
       "      <td>C#</td>\n",
       "      <td>503</td>\n",
       "      <td>7,013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        Description  \\\n",
       "0         libsdl-org /                           Simple Directmedia Layer   \n",
       "1              Azure /                         Azure Quickstart Templates   \n",
       "2           system76 /              System76 Launch Configurable Keyboard   \n",
       "3        benbjohnson /               Streaming S3 replication for SQLite.   \n",
       "4          mbround18 /      Valheim Docker server with Odin the CLI tool.   \n",
       "5           deepmind /  This repository contains implementations and i...   \n",
       "6       satwikkansal /                              What the f*ck Python?   \n",
       "7              vlang /  Simple, fast, safe, compiled language for deve...   \n",
       "8      serhii-londar /  🚀 Awesome list of open source applications for...   \n",
       "9         PowerShell /                       PowerShell for every system!   \n",
       "10              ossu /  🎓 Path to a free self-taught education in Comp...   \n",
       "11          iptv-org /  Collection of 5000+ publicly available IPTV ch...   \n",
       "12         streamich /                                    React Hooks — 👍   \n",
       "13             Azure /  The source for REST API specifications for Mic...   \n",
       "14     adityatelange /               A fast, clean, responsive Hugo theme   \n",
       "15          reactend /             React renderer to build Node.js server   \n",
       "16      flybywiresim /  The A32NX Project is a community driven open s...   \n",
       "17         Dimbreath /  Repository containing the game data for the ga...   \n",
       "18         hashicorp /  A tool for secrets management, encryption as a...   \n",
       "19  abhishekkrthakur /  Run VSCode (codeserver) on Google Colab or Kag...   \n",
       "20       florisboard /  An open-source keyboard for Android. Currently...   \n",
       "21        goreleaser /  Deliver Go binaries as fast and easily as poss...   \n",
       "\n",
       "            Language Conutrybuted Muted_Star  \n",
       "0                  C           22        420  \n",
       "1         PowerShell       12,234      9,416  \n",
       "2              Shell           14        737  \n",
       "3                 Go           32      1,922  \n",
       "4               Rust           12         70  \n",
       "5   Jupyter Notebook          978      5,055  \n",
       "6             Python        2,095     24,436  \n",
       "7                  V        1,326     22,167  \n",
       "8              Swift        1,648     24,625  \n",
       "9                 C#        3,923     24,249  \n",
       "10        JavaScript       10,823     74,976  \n",
       "11        TypeScript          861     27,557  \n",
       "12        TypeScript        1,373     19,578  \n",
       "13              HTML        2,649      1,052  \n",
       "14        JavaScript          230        507  \n",
       "15        JavaScript            8        162  \n",
       "16                Go          466      2,949  \n",
       "17            Python           20         69  \n",
       "18            Kotlin        2,793     20,024  \n",
       "19                Go          144      1,047  \n",
       "20            Python           48        534  \n",
       "21                C#          503      7,013  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_Repository=pd.DataFrame([])\n",
    "Trending_Repository['Name']=Repository_Name[:22]\n",
    "Trending_Repository['Description']=Description[:22]\n",
    "Trending_Repository['Language']=Language[:22]\n",
    "Trending_Repository['Conutrybuted']=Muted[:22]\n",
    "Trending_Repository['Muted_Star']=Muted_Star[:22]\n",
    "Trending_Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****QUES5.... Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6=\"https://www.billboard.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name =[]\n",
    "Singer=[]\n",
    "rank=[]\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]')       \n",
    "top100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '1', '1', '2', '5', '5', '1', '8', '3', '10', '9', '12', '13', '2', '6', '8', '15', '18', '3', '12', '5', '6', '23', '2', '25', '9', '27', '6', '1', '29', '31', '32', '24', '9', '6', '25', '37', '15', '39', '40', '13', '39', '43', '1', '29', '1', '47', '25', '2', '50', '51', '47', '53', '54', '53', '56', '57', '58', '39', '60', '61', '62', '63', '64', '65', '34', '52', '2', '58', '53', '71', '72', '22', '74', '75', '45', '46', '59', '42', '37', '81', '82', '83', '42', '8', '86', '73', '88', '48', '82', '91', '92', '87', '62', '62', '96', '54', '62', '95', '10']\n"
     ]
    }
   ],
   "source": [
    "rb=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in rb:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "print(len(rank),rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Drivers License', 'Mood', 'Blinding Lights', '34+35', 'Levitating', 'Go Crazy', 'Positions', 'Save Your Tears', 'Holy', 'Whoopty', 'Good Days', 'Lonely', 'What You Know Bout Love', 'Therefore I Am', 'For The Night', 'Bang!', 'Better Together', 'Streets', 'I Hope', 'Body', 'Dakiti', 'Lemonade', 'You Broke Me First.', 'Laugh Now Cry Later', \"My Ex's Best Friend\", 'Wasted On You', \"You're Mines Still\", 'Anyone', 'Willow', 'On Me', 'Good Time', 'Sand In My Boots', 'Throat Baby (Go Baby)', 'Before You Go', '7 Summers', 'Starting Over', 'Back In Blood', 'More Than My Hometown', 'Finesse Out The Gang Way', 'Hole In The Bottle', 'Kings & Queens', 'Best Friend', 'Cry Baby', 'Rockstar', 'Afterglow', 'Dynamite', 'Happy Does', \"Somebody's Problem\", 'Whats Poppin', 'Put Your Records On', 'Damage', 'Without You', \"Should've Ducked\", 'Just The Way', 'Beers And Sunshine', 'Down To One', \"What's Your Country Song\", 'Beat Box', 'Diamonds', 'The Good Ones', 'Golden', 'Buss It', 'Goosebumps', 'Monsters', 'Long Live', 'Tyler Herro', 'Cover Me Up', 'Forever After All', 'Back To The Streets', \"Still Trappin'\", 'Gravity', 'Bichota', 'Bad Boy', 'Baila Conmigo', 'Lady', 'Still Goin Down', '865', 'So Done', 'Warning', 'Holiday', 'Hell Of A View', 'Girl Like Me', \"Momma's House\", 'Big, Big Plans', 'Monster', 'Heat Waves', 'Stay Down', 'Somebody Like That', 'Skin', 'Moonwalking In Calabasas', 'Kanye Krazy', 'Pick Up Your Feelings', 'You Got It', 'One Too Many', 'Backdoor', 'Fake Woke', 'Prisoner', 'Dangerous', 'Almost Maybes', 'Mr. Right Now']\n"
     ]
    }
   ],
   "source": [
    "son=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in son:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "print(len(Song_Name),Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Olivia Rodrigo', '24kGoldn Featuring iann dior', 'The Weeknd', 'Ariana Grande', 'Dua Lipa Featuring DaBaby', 'Chris Brown & Young Thug', 'Ariana Grande', 'The Weeknd', 'Justin Bieber Featuring Chance The Rapper', 'CJ', 'SZA', 'Justin Bieber & benny blanco', 'Pop Smoke', 'Billie Eilish', 'Pop Smoke Featuring Lil Baby & DaBaby', 'AJR', 'Luke Combs', 'Doja Cat', 'Gabby Barrett Featuring Charlie Puth', 'Megan Thee Stallion', 'Bad Bunny & Jhay Cortez', 'Internet Money & Gunna Featuring Don Toliver & NAV', 'Tate McRae', 'Drake Featuring Lil Durk', 'Machine Gun Kelly X blackbear', 'Morgan Wallen', 'Yung Bleu Featuring Drake', 'Justin Bieber', 'Taylor Swift', 'Lil Baby', 'Niko Moon', 'Morgan Wallen', 'BRS Kash', 'Lewis Capaldi', 'Morgan Wallen', 'Chris Stapleton', 'Pooh Shiesty Featuring Lil Durk', 'Morgan Wallen', 'Lil Durk Featuring Lil Baby', 'Kelsea Ballerini', 'Ava Max', 'Saweetie Featuring Doja Cat', 'Megan Thee Stallion Featuring DaBaby', 'DaBaby Featuring Roddy Ricch', 'Ed Sheeran', 'BTS', 'Kenny Chesney', 'Morgan Wallen', 'Jack Harlow Featuring DaBaby, Tory Lanez & Lil Wayne', 'Ritt Momney', 'H.E.R.', 'The Kid LAROI', 'Lil Durk Featuring Pooh Shiesty', 'Parmalee x Blanco Brown', 'Darius Rucker', 'Luke Bryan', 'Thomas Rhett', 'SpotemGottem', 'Sam Smith', 'Gabby Barrett', 'Harry Styles', 'Erica Banks', 'Travis Scott & HVME', 'All Time Low Featuring Demi Lovato & blackbear', 'Florida Georgia Line', 'Jack Harlow', 'Morgan Wallen', 'Luke Combs', 'Saweetie Featuring Jhene Aiko', 'Lil Durk & King Von', 'Brent Faiyaz & DJ Dahi Featuring Tyler, The Creator', 'Karol G', 'Juice WRLD & Young Thug', 'Selena Gomez With Rauw Alejandro', 'Brett Young', 'Morgan Wallen', 'Morgan Wallen', 'The Kid LAROI', 'Morgan Wallen', 'Lil Nas X', 'Eric Church', 'Black Eyed Peas X Shakira', 'Dustin Lynch', 'Chris Lane', 'Shawn Mendes & Justin Bieber', 'Glass Animals', 'Lil Durk, 6LACK & Young Thug', 'Tenille Arts', 'Sabrina Carpenter', 'DDG', 'Lil Durk', 'Jazmine Sullivan', 'VEDO', 'Keith Urban Duet With P!nk', 'Lil Durk', 'Tom MacDonald', 'Miley Cyrus Featuring Dua Lipa', 'Morgan Wallen', 'Jordan Davis', '21 Savage & Metro Boomin Featuring Drake']\n"
     ]
    }
   ],
   "source": [
    "sin=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in sin:\n",
    "    if i.text is None :\n",
    "        Singer.append(\"--\") \n",
    "    else:\n",
    "        Singer.append(i.text)\n",
    "print(len(Singer),Singer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1', '2', '3', '4', '5', '6', '7', '14', '8', '16', '9', '13', '19', '12', '11', '10', '15', '25', '17', '18', '20', '21', '27', '22', '34', '31', '32', '26', '28', '29', '37', '38', '24', '33', '23', '36', '40', '30', '-', '42', '35', '45', '54', '41', '39', '46', '50', '43', '44', '55', '52', '47', '-', '56', '53', '58', '59', '60', '49', '64', '65', '67', '73', '69', '68', '63', '74', '66', '61', '84', '-', '75', '57', '-', '86', '72', '77', '79', '76', '71', '90', '85', '87', '82', '70', '91', '-', '89', '48', '88', '-', '-', '95', '96', '-', '-', '81', '-', '-', '80']\n"
     ]
    }
   ],
   "source": [
    "lwr=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        Last_Week.append(\"--\") \n",
    "    else:\n",
    "        Last_Week.append(i.text)\n",
    "print(len(Last_Week),Last_Week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['4', '26', '61', '14', '18', '39', '15', '8', '20', '13', '6', '16', '22', '13', '31', '31', '18', '4', '58', '11', '14', '25', '24', '25', '25', '4', '9', '5', '8', '9', '18', '4', '16', '50', '24', '23', '5', '32', '1', '16', '26', '4', '9', '41', '7', '24', '12', '8', '51', '16', '8', '9', '1', '6', '8', '6', '7', '3', '20', '6', '15', '4', '3', '6', '5', '15', '5', '15', '11', '6', '1', '10', '3', '1', '4', '7', '4', '13', '4', '12', '4', '4', '4', '18', '11', '3', '4', '3', '2', '6', '1', '2', '6', '8', '4', '1', '11', '3', '2', '18']\n"
     ]
    }
   ],
   "source": [
    "wob=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in wob:\n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "print(len(Weeks_on_board),Weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Singer / Crew</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Drivers License</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mood</td>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34+35</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Fake Woke</td>\n",
       "      <td>Tom MacDonald</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>54</td>\n",
       "      <td>Prisoner</td>\n",
       "      <td>Miley Cyrus Featuring Dua Lipa</td>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>62</td>\n",
       "      <td>Dangerous</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>95</td>\n",
       "      <td>Almost Maybes</td>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>Mr. Right Now</td>\n",
       "      <td>21 Savage &amp; Metro Boomin Featuring Drake</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak_rank        Song_Name                             Singer / Crew  \\\n",
       "0          1  Drivers License                            Olivia Rodrigo   \n",
       "1          1             Mood              24kGoldn Featuring iann dior   \n",
       "2          1  Blinding Lights                                The Weeknd   \n",
       "3          2            34+35                             Ariana Grande   \n",
       "4          5       Levitating                 Dua Lipa Featuring DaBaby   \n",
       "..       ...              ...                                       ...   \n",
       "95        96        Fake Woke                             Tom MacDonald   \n",
       "96        54         Prisoner            Miley Cyrus Featuring Dua Lipa   \n",
       "97        62        Dangerous                             Morgan Wallen   \n",
       "98        95    Almost Maybes                              Jordan Davis   \n",
       "99        10    Mr. Right Now  21 Savage & Metro Boomin Featuring Drake   \n",
       "\n",
       "   Last_Week_Rank Weeks_on_board  \n",
       "0               1              4  \n",
       "1               2             26  \n",
       "2               3             61  \n",
       "3               4             14  \n",
       "4               5             18  \n",
       "..            ...            ...  \n",
       "95              -              1  \n",
       "96             81             11  \n",
       "97              -              3  \n",
       "98              -              2  \n",
       "99             80             18  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Song=pd.DataFrame([])\n",
    "Top_Song['Peak_rank']=rank\n",
    "Top_Song['Song_Name']=Song_Name\n",
    "Top_Song['Singer / Crew']=Singer\n",
    "Top_Song['Last_Week_Rank']=Last_Week\n",
    "Top_Song['Weeks_on_board']=Weeks_on_board\n",
    "Top_Song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***QUES9...Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_7=\"https://www.naukri.com/data-science-jobs?k=data%20science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_Title =[]\n",
    "Company_Name=[]\n",
    "Skill=[]\n",
    "Salary=[]\n",
    "Location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Data Science/AIML Intern', 'Machine Learning-Python, AI / ML developer, Data Science', 'Data Science', 'Data Science Engineer - Statistical Modeling/ Machine Learning', 'Full Stack Data Science Engineer - Machine Learning/Deep Learning', 'Data Science', 'Data Science Engineer', 'Data Science Team Lead - Retail', 'Data Science - Team Lead (CRM)', 'BI Analyst ( Data Science )', 'Urgently Hiring Trainee - Data Science :: Hitech Isolutions LLP!!!!', 'Data Science Engineer - Java / Python / R Developer', 'Data Science', 'Senior Manager Ops Data Science', 'Trainer: Machine Learning, Data Science,Internet of Things,3D Printing', 'Senior Data Scientist - Data Sciences', 'Online Faculty For Data Science & Business Analytics', 'Freshers/Internship - Data Science/ Machine Learning / AI', 'Senior Analytics Consultant-Data Science-Pune', 'Data Science Engineer,SMART MFG & AI']\n"
     ]
    }
   ],
   "source": [
    " jt=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in jt:\n",
    "    if i.text is None :\n",
    "        Job_Title.append(\"--\") \n",
    "    else:\n",
    "        Job_Title.append(i.text)\n",
    "print(len(Job_Title),Job_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Hewlett Packard Enterprise', 'Infomize Technologies', 'Capgemini Technology Services India Limited', 'Lera Technologies Pvt. Ltd', 'Thinkbridge', 'Diverse Lynx', 'Everwell Health Solutions Pvt Ltd', 'Shell India Markets Private Limited', 'Shell India Markets Private Limited', 'American Bureau of Shipping', 'Hi-Tech iSolutions LLP', 'Intellicar Telematics Pvt Ltd', 'Cybage', 'RANDSTAD INDIA PVT LTD', 'SYMBIOSIS SKILLS AND PROFESSIONAL UNIVERSITY', 'GEP', 'LINC Education', 'IIBM', 'eClerx Services Ltd.', 'Micron Semiconductor Asia Pte Ltd']\n"
     ]
    }
   ],
   "source": [
    "cn=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in cn:\n",
    "    if i.text is None :\n",
    "        Company_Name.append(\"--\") \n",
    "    else:\n",
    "        Company_Name.append(i.text)\n",
    "print(len(Company_Name),Company_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Not disclosed', '2,00,000 - 7,00,000 PA.', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', '50,000 - 3,00,000 PA.', 'Not disclosed', 'Not disclosed', '18,00,000 - 30,00,000 PA.', '50,000 - 1,00,000 PA.', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed', 'Not disclosed']\n"
     ]
    }
   ],
   "source": [
    "sal=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']/span\")\n",
    "for i in sal:\n",
    "    if i.text is None :\n",
    "        Salary.append(\"--\") \n",
    "    else:\n",
    "        Salary.append(i.text)\n",
    "print(len(Salary),Salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Bengaluru', 'Ahmedabad', 'Chennai', 'India', 'India', 'Gurgaon', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Chennai', 'Ahmedabad', 'Bengaluru', 'Pune', 'Bengaluru', 'Pune(Kiwale)', 'Hyderabad', 'Pune, Mumbai, Bengaluru', 'Chennai, Hyderabad', 'Pune', 'Hyderabad']\n"
     ]
    }
   ],
   "source": [
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in loc:\n",
    "    if i.text is None :\n",
    "        Location.append(\"--\") \n",
    "    else:\n",
    "        Location.append(i.text)\n",
    "print(len(Location),Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['IT Skills\\nPython\\nTesting\\nMachine Learning\\nComputer science\\nBusiness objects\\nData analysis\\ndata science', 'Data Processing\\nIT Skills\\nJava\\nTensorflow\\nArtificial Intelligence\\nNatural Language Processing\\nData Analysis\\nData Extraction', 'IT Skills\\nPython\\nTesting\\nData Science\\nsoftware architecture\\ndeep learning\\nData analysis\\ndata science', 'IT Skills\\nPython\\nMachine Learning\\nArtificial Intelligence\\nData Science\\nPredictive Modeling\\nData Scientist\\nArtificial Intelligence', 'IT Skills\\nPython\\nTesting\\nCloud\\nAWS\\nTableau\\nPower BI\\nAzure', 'IT Skills\\nPython\\nData Science\\nMachine Learning\\nSupply chain\\nData analysis\\nPrototype\\nConsulting', 'IT Skills\\nPython\\nBig Data\\nProduct management\\nComputer science\\nData analysis\\nData modeling\\nHealthcare', 'Multivariate Analysis\\nData Science\\nR\\nFactor Analysis\\nBI\\nMarket Basket Analysis\\nTime Series\\nData Analytics', 'Direct Marketing\\nR\\nFactor Analysis\\nTeam Management Skills\\nCustomer Analytics\\nTime Series\\nMarket Basket Analysis\\nMachine Learning', 'Microstrategy\\nBusiness objects\\nSAP\\nSAS\\nTIBCO\\nTeradata\\nBusiness intelligence\\nmicrosoft', 'Data Science', 'Data Science\\nJava\\nHive\\nR\\nScala\\nSpark\\nmachine learning\\nstatistical analysis', 'IT Skills\\nData Science\\nMachine Learning\\nStatistical programming\\nData analysis\\nStatistical modeling\\nSAS\\ndata science', 'Project Management\\nArtificial Intelligence\\nPerformance Metrics\\nStudent Engagement\\nSales\\nExecution\\nSenior Management\\nPeople Management', 'Data Science\\n3D Printing\\nMachine Learning\\nBig Data Analytics\\nSoftware Development\\nArtificial Intelligence\\nInternet of Things -IOT', 'Procurement\\nComputer science\\nCoding\\nAnalytical\\nMachine learning\\nMongoDB\\nOpen source\\nPython', 'Business Analytics\\nteaching\\nData Science\\nBig Data Analytics\\nData Science Faculty\\neducation\\nData Wrangling\\nuniversity', 'IT Skills\\nPython\\nData Science\\nr\\nArtificial Intelligence\\nNatural Language Processing\\nMachine Learning\\nPython', 'Data Science\\nPredictive Modeling\\nNetwork Planning\\nInventory Planning\\nDemand Planning\\nForecasting\\nAnalytics\\nPython', 'SQL Server\\nData Science Engineer\\nSAP\\nSAP HANA\\nPower BI\\nSSIS\\nJDA\\nSalesforce']\n"
     ]
    }
   ],
   "source": [
    "sk=driver.find_elements_by_xpath(\"//ul[@class='tags has-description']\")\n",
    "for i in sk:\n",
    "    if i.text is None :\n",
    "        Skill.append(\"--\") \n",
    "    else:\n",
    "        Skill.append(i.text)\n",
    "print(len(Skill),Skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science/AIML Intern</td>\n",
       "      <td>IT Skills\\nPython\\nTesting\\nMachine Learning\\n...</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning-Python, AI / ML developer, Da...</td>\n",
       "      <td>Data Processing\\nIT Skills\\nJava\\nTensorflow\\n...</td>\n",
       "      <td>Infomize Technologies</td>\n",
       "      <td>2,00,000 - 7,00,000 PA.</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>IT Skills\\nPython\\nTesting\\nData Science\\nsoft...</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Engineer - Statistical Modeling/ ...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nArtificia...</td>\n",
       "      <td>Lera Technologies Pvt. Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Stack Data Science Engineer - Machine Lea...</td>\n",
       "      <td>IT Skills\\nPython\\nTesting\\nCloud\\nAWS\\nTablea...</td>\n",
       "      <td>Thinkbridge</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>IT Skills\\nPython\\nData Science\\nMachine Learn...</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>IT Skills\\nPython\\nBig Data\\nProduct managemen...</td>\n",
       "      <td>Everwell Health Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Team Lead - Retail</td>\n",
       "      <td>Multivariate Analysis\\nData Science\\nR\\nFactor...</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science - Team Lead (CRM)</td>\n",
       "      <td>Direct Marketing\\nR\\nFactor Analysis\\nTeam Man...</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BI Analyst ( Data Science )</td>\n",
       "      <td>Microstrategy\\nBusiness objects\\nSAP\\nSAS\\nTIB...</td>\n",
       "      <td>American Bureau of Shipping</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Urgently Hiring Trainee - Data Science :: Hite...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Hi-Tech iSolutions LLP</td>\n",
       "      <td>50,000 - 3,00,000 PA.</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Science Engineer - Java / Python / R Deve...</td>\n",
       "      <td>Data Science\\nJava\\nHive\\nR\\nScala\\nSpark\\nmac...</td>\n",
       "      <td>Intellicar Telematics Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>IT Skills\\nData Science\\nMachine Learning\\nSta...</td>\n",
       "      <td>Cybage</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Manager Ops Data Science</td>\n",
       "      <td>Project Management\\nArtificial Intelligence\\nP...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>18,00,000 - 30,00,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Trainer: Machine Learning, Data Science,Intern...</td>\n",
       "      <td>Data Science\\n3D Printing\\nMachine Learning\\nB...</td>\n",
       "      <td>SYMBIOSIS SKILLS AND PROFESSIONAL UNIVERSITY</td>\n",
       "      <td>50,000 - 1,00,000 PA.</td>\n",
       "      <td>Pune(Kiwale)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Data Scientist - Data Sciences</td>\n",
       "      <td>Procurement\\nComputer science\\nCoding\\nAnalyti...</td>\n",
       "      <td>GEP</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Online Faculty For Data Science &amp; Business Ana...</td>\n",
       "      <td>Business Analytics\\nteaching\\nData Science\\nBi...</td>\n",
       "      <td>LINC Education</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Mumbai, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Freshers/Internship - Data Science/ Machine Le...</td>\n",
       "      <td>IT Skills\\nPython\\nData Science\\nr\\nArtificial...</td>\n",
       "      <td>IIBM</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Analytics Consultant-Data Science-Pune</td>\n",
       "      <td>Data Science\\nPredictive Modeling\\nNetwork Pla...</td>\n",
       "      <td>eClerx Services Ltd.</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science Engineer,SMART MFG &amp; AI</td>\n",
       "      <td>SQL Server\\nData Science Engineer\\nSAP\\nSAP HA...</td>\n",
       "      <td>Micron Semiconductor Asia Pte Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "0                            Data Science/AIML Intern   \n",
       "1   Machine Learning-Python, AI / ML developer, Da...   \n",
       "2                                        Data Science   \n",
       "3   Data Science Engineer - Statistical Modeling/ ...   \n",
       "4   Full Stack Data Science Engineer - Machine Lea...   \n",
       "5                                        Data Science   \n",
       "6                               Data Science Engineer   \n",
       "7                     Data Science Team Lead - Retail   \n",
       "8                      Data Science - Team Lead (CRM)   \n",
       "9                         BI Analyst ( Data Science )   \n",
       "10  Urgently Hiring Trainee - Data Science :: Hite...   \n",
       "11  Data Science Engineer - Java / Python / R Deve...   \n",
       "12                                       Data Science   \n",
       "13                    Senior Manager Ops Data Science   \n",
       "14  Trainer: Machine Learning, Data Science,Intern...   \n",
       "15              Senior Data Scientist - Data Sciences   \n",
       "16  Online Faculty For Data Science & Business Ana...   \n",
       "17  Freshers/Internship - Data Science/ Machine Le...   \n",
       "18      Senior Analytics Consultant-Data Science-Pune   \n",
       "19               Data Science Engineer,SMART MFG & AI   \n",
       "\n",
       "                                                Skill  \\\n",
       "0   IT Skills\\nPython\\nTesting\\nMachine Learning\\n...   \n",
       "1   Data Processing\\nIT Skills\\nJava\\nTensorflow\\n...   \n",
       "2   IT Skills\\nPython\\nTesting\\nData Science\\nsoft...   \n",
       "3   IT Skills\\nPython\\nMachine Learning\\nArtificia...   \n",
       "4   IT Skills\\nPython\\nTesting\\nCloud\\nAWS\\nTablea...   \n",
       "5   IT Skills\\nPython\\nData Science\\nMachine Learn...   \n",
       "6   IT Skills\\nPython\\nBig Data\\nProduct managemen...   \n",
       "7   Multivariate Analysis\\nData Science\\nR\\nFactor...   \n",
       "8   Direct Marketing\\nR\\nFactor Analysis\\nTeam Man...   \n",
       "9   Microstrategy\\nBusiness objects\\nSAP\\nSAS\\nTIB...   \n",
       "10                                       Data Science   \n",
       "11  Data Science\\nJava\\nHive\\nR\\nScala\\nSpark\\nmac...   \n",
       "12  IT Skills\\nData Science\\nMachine Learning\\nSta...   \n",
       "13  Project Management\\nArtificial Intelligence\\nP...   \n",
       "14  Data Science\\n3D Printing\\nMachine Learning\\nB...   \n",
       "15  Procurement\\nComputer science\\nCoding\\nAnalyti...   \n",
       "16  Business Analytics\\nteaching\\nData Science\\nBi...   \n",
       "17  IT Skills\\nPython\\nData Science\\nr\\nArtificial...   \n",
       "18  Data Science\\nPredictive Modeling\\nNetwork Pla...   \n",
       "19  SQL Server\\nData Science Engineer\\nSAP\\nSAP HA...   \n",
       "\n",
       "                                    Company_Name                     Salary  \\\n",
       "0                     Hewlett Packard Enterprise              Not disclosed   \n",
       "1                          Infomize Technologies    2,00,000 - 7,00,000 PA.   \n",
       "2    Capgemini Technology Services India Limited              Not disclosed   \n",
       "3                     Lera Technologies Pvt. Ltd              Not disclosed   \n",
       "4                                    Thinkbridge              Not disclosed   \n",
       "5                                   Diverse Lynx              Not disclosed   \n",
       "6              Everwell Health Solutions Pvt Ltd              Not disclosed   \n",
       "7            Shell India Markets Private Limited              Not disclosed   \n",
       "8            Shell India Markets Private Limited              Not disclosed   \n",
       "9                    American Bureau of Shipping              Not disclosed   \n",
       "10                        Hi-Tech iSolutions LLP      50,000 - 3,00,000 PA.   \n",
       "11                 Intellicar Telematics Pvt Ltd              Not disclosed   \n",
       "12                                        Cybage              Not disclosed   \n",
       "13                        RANDSTAD INDIA PVT LTD  18,00,000 - 30,00,000 PA.   \n",
       "14  SYMBIOSIS SKILLS AND PROFESSIONAL UNIVERSITY      50,000 - 1,00,000 PA.   \n",
       "15                                           GEP              Not disclosed   \n",
       "16                                LINC Education              Not disclosed   \n",
       "17                                          IIBM              Not disclosed   \n",
       "18                          eClerx Services Ltd.              Not disclosed   \n",
       "19             Micron Semiconductor Asia Pte Ltd              Not disclosed   \n",
       "\n",
       "                   Location  \n",
       "0                 Bengaluru  \n",
       "1                 Ahmedabad  \n",
       "2                   Chennai  \n",
       "3                     India  \n",
       "4                     India  \n",
       "5                   Gurgaon  \n",
       "6                 Bengaluru  \n",
       "7                 Bengaluru  \n",
       "8                 Bengaluru  \n",
       "9                   Chennai  \n",
       "10                Ahmedabad  \n",
       "11                Bengaluru  \n",
       "12                     Pune  \n",
       "13                Bengaluru  \n",
       "14             Pune(Kiwale)  \n",
       "15                Hyderabad  \n",
       "16  Pune, Mumbai, Bengaluru  \n",
       "17       Chennai, Hyderabad  \n",
       "18                     Pune  \n",
       "19                Hyderabad  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB=pd.DataFrame([])\n",
    "JOB['Job_Title']=Job_Title\n",
    "JOB['Skill']=Skill\n",
    "JOB['Company_Name']=Company_Name\n",
    "JOB['Salary']=Salary\n",
    "JOB['Location']=Location\n",
    "JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****QUES7....Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_9=\"https://www.imdb.com/list/ls095964455/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'You', 'Dexter', 'Fear the Walking Dead', 'Family Guy', 'The Blacklist', 'Lost', 'Peaky Blinders', 'House', 'Quantico', 'Orphan Black', 'Homeland', 'Blindspot', \"DC's Legends of Tomorrow\", \"The Handmaid's Tale\", 'Chilling Adventures of Sabrina', 'The Good Doctor', 'Jane the Virgin', 'Glee', 'South Park', 'Brooklyn Nine-Nine', 'Under the Dome', 'The Umbrella Academy', 'True Detective', 'The OA', 'Desperate Housewives', 'Better Call Saul', 'Bates Motel', 'The Punisher', 'Atypical', 'Dynasty', 'This Is Us', 'The Good Place', 'Iron Fist', 'The Rain', 'Mindhunter', 'Revenge', 'Luke Cage', 'Scandal', 'The Defenders', 'Big Little Lies', 'Insatiable', 'The Mentalist', 'The Crown', 'Chernobyl', 'iZombie', 'Reign', 'A Series of Unfortunate Events', 'Criminal Minds', 'Scream: The TV Series', 'The Haunting of Hill House']\n"
     ]
    }
   ],
   "source": [
    "mname=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/h3/a\")\n",
    "for i in mname:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['(2011–2019)', '(2016– )', '(2010– )', '(2017–2020)', '(2014–2020)', '(2013–2019)', '(2017– )', '(2005– )', '(2014– )', '(2012–2020)', '(2017– )', '(2007–2019)', '(2011– )', '(2010–2017)', '(2013–2020)', '(2010–2017)', '(2009–2017)', '(2011– )', '(2008–2013)', '(2016– )', '(2005–2020)', '(2005–2017)', '(2014–2020)', '(2011–2017)', '(1989– )', '(2011–2018)', '(2015–2017)', '(2015–2018)', '(1994–2004)', '(2005–2014)', '(2011–2019)', '(2015–2019)', '(2013–2018)', '(2015–2021)', '(2007–2012)', '(2015–2018)', '(2014–2019)', '(2016– )', '(2015–2019)', '(2009–2020)', '(2013– )', '(2016–2019)', '(2017–2019)', '(2013–2018)', '(2017–2020)', '(2018– )', '(2019– )', '(2011–2021)', '(2011–2018)', '(2013–2020)', '(2018– )', '(2006–2021)', '(2015– )', '(1999– )', '(2013– )', '(2004–2010)', '(2013– )', '(2004–2012)', '(2015–2018)', '(2013–2017)', '(2011–2020)', '(2015–2020)', '(2016– )', '(2017– )', '(2018–2020)', '(2017– )', '(2014–2019)', '(2009–2015)', '(1997– )', '(2013–2022)', '(2013–2015)', '(2019– )', '(2014– )', '(2016–2019)', '(2004–2012)', '(2015–2021)', '(2013–2017)', '(2017–2019)', '(2017–2021)', '(2017– )', '(2016– )', '(2016–2020)', '(2017–2018)', '(2018–2020)', '(2017–2019)', '(2011–2015)', '(2016–2018)', '(2012–2018)', '(2017)', '(2017–2019)', '(2018–2019)', '(2008–2015)', '(2016– )', '(2019)', '(2015–2019)', '(2013–2017)', '(2017–2019)', '(2005–2020)', '(2015–2019)', '(2018)']\n"
     ]
    }
   ],
   "source": [
    "ys=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in ys:\n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text)\n",
    "print(len(Year_span),Year_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Mystery', 'Comedy, Romance', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama', 'Comedy, Drama', 'Comedy', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Crime, Drama, Mystery', 'Drama, Horror, Sci-Fi', 'Animation, Comedy', 'Crime, Drama, Mystery', 'Adventure, Drama, Fantasy', 'Crime, Drama', 'Drama, Mystery', 'Crime, Drama, Mystery', 'Action, Drama, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Crime, Drama', 'Action, Adventure, Drama', 'Drama, Sci-Fi, Thriller', 'Drama, Fantasy, Horror', 'Drama', 'Comedy', 'Comedy, Drama, Music', 'Animation, Comedy', 'Comedy, Crime', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Drama, Fantasy, Mystery', 'Comedy, Drama, Mystery', 'Crime, Drama', 'Drama, Horror, Mystery', 'Action, Crime, Drama', 'Comedy, Drama', 'Drama', 'Comedy, Drama, Romance', 'Comedy, Drama, Fantasy', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Crime, Drama, Thriller', 'Drama, Mystery, Thriller', 'Action, Crime, Drama', 'Drama, Thriller', 'Action, Adventure, Crime', 'Crime, Drama, Mystery', 'Comedy, Drama, Thriller', 'Crime, Drama, Mystery', 'Biography, Drama, History', 'Drama, History, Thriller', 'Comedy, Crime, Drama', 'Drama, Fantasy', 'Adventure, Comedy, Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Horror', 'Drama, Horror, Mystery']\n"
     ]
    }
   ],
   "source": [
    "gnr=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in gnr:\n",
    "    if i.text is None :\n",
    "        Genres.append(\"--\") \n",
    "    else:\n",
    "        Genres.append(i.text)\n",
    "print(len(Genres),Genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['57 min', '51 min', '44 min', '60 min', '43 min', '59 min', '45 min', '41 min', '43 min', '42 min', '70 min', '22 min', '60 min', '88 min', '44 min', '44 min', '43 min', '60 min', '49 min', '42 min', '44 min', '44 min', '43 min', '41 min', '22 min', '60 min', '49 min', '54 min', '22 min', '22 min', '44 min', '49 min', '45 min', '43 min', '42 min', '60 min', '42 min', '62 min', '56 min', '22 min', '23 min', '42 min', '25 min', '51 min', '60 min', '60 min', '45 min', '46 min', '22 min', '45 min', '45 min', '53 min', '44 min', '22 min', '43 min', '44 min', '60 min', '44 min', '42 min', '44 min', '55 min', '42 min', '42 min', '60 min', '60 min', '41 min', '60 min', '44 min', '22 min', '22 min', '43 min', '60 min', '55 min', '60 min', '45 min', '46 min', '45 min', '53 min', '30 min', '42 min', '45 min', '22 min', '55 min', '45 min', '60 min', '44 min', '55 min', '43 min', '50 min', '60 min', '45 min', '43 min', '58 min', '330 min', '42 min', '42 min', '50 min', '42 min', '45 min', '572 min']\n"
     ]
    }
   ],
   "source": [
    "rt=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in rt:\n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "print(len(Run_time),Run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['9.3', '8.7', '8.2', '7.6', '7.6', '8.1', '6.9', '7.6', '7.7', '7.5', '8.3', '8.1', '8.8', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.6', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.5', '8.6', '8.2', '6.3', '7.4', '8.3', '7.8', '8.6', '7.9', '8.4', '9.2', '6.6', '8.1', '8.7', '8.8', '7.6', '8.3', '8.6', '7.7', '7.5', '7.7', '8.6', '6.9', '8.1', '8', '8.3', '8.8', '8.7', '6.7', '8.3', '8.3', '7.4', '6.8', '8.4', '7.5', '8.2', '7.8', '6.7', '8.7', '8.4', '6.6', '8', '9', '7.8', '7.5', '8.7', '8.2', '8.5', '8.3', '7.3', '8.7', '8.2', '6.5', '6.3', '8.6', '7.8', '7.3', '7.7', '7.3', '8.5', '6.5', '8.1', '8.7', '9.4', '7.8', '7.5', '7.8', '8.1', '7.2', '8.6']\n"
     ]
    }
   ],
   "source": [
    "rate=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "for i in rate:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "print(len(Ratings),Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['1,769,233', '821,635', '853,072', '256,113', '216,348', '278,856', '117,899', '250,776', '305,181', '407,564', '297,878', '722,994', '444,293', '806,945', '431,900', '152,221', '282,921', '277,394', '1,464,320', '232,277', '392,480', '476,193', '129,236', '126,721', '365,570', '208,536', '357,416', '362,447', '827,169', '602,614', '363,473', '333,236', '117,471', '111,147', '154,306', '139,380', '211,829', '428,010', '193,178', '355,035', '375,544', '53,291', '145,873', '466,799', '283,547', '48,131', '158,002', '203,085', '192,273', '199,706', '143,376', '646,228', '112,413', '304,550', '197,104', '495,446', '348,052', '414,569', '57,195', '101,357', '312,706', '66,628', '91,944', '171,996', '77,461', '62,811', '38,745', '136,690', '331,433', '225,169', '101,168', '158,818', '499,232', '90,530', '115,632', '323,679', '96,965', '184,269', '60,233', '14,818', '106,384', '114,922', '114,697', '30,800', '216,929', '112,514', '116,798', '67,246', '90,775', '156,411', '22,561', '165,443', '149,259', '541,112', '60,460', '43,572', '53,853', '161,105', '34,082', '182,229']\n"
     ]
    }
   ],
   "source": [
    "v=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "print(len(Votes),Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>57 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,769,233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>51 min</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>821,635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010– )</td>\n",
       "      <td>44 min</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.2</td>\n",
       "      <td>853,072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>60 min</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>216,348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>7.5</td>\n",
       "      <td>43,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>50 min</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>53,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>161,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>45 min</td>\n",
       "      <td>Crime, Drama, Horror</td>\n",
       "      <td>7.2</td>\n",
       "      <td>34,082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>572 min</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>182,229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span Run_time  \\\n",
       "0                  Game of Thrones  (2011–2019)   57 min   \n",
       "1                  Stranger Things     (2016– )   51 min   \n",
       "2                 The Walking Dead     (2010– )   44 min   \n",
       "3                   13 Reasons Why  (2017–2020)   60 min   \n",
       "4                          The 100  (2014–2020)   43 min   \n",
       "..                             ...          ...      ...   \n",
       "95                           Reign  (2013–2017)   42 min   \n",
       "96  A Series of Unfortunate Events  (2017–2019)   50 min   \n",
       "97                  Criminal Minds  (2005–2020)   42 min   \n",
       "98           Scream: The TV Series  (2015–2019)   45 min   \n",
       "99      The Haunting of Hill House       (2018)  572 min   \n",
       "\n",
       "                      Genres Ratings      Votes  \n",
       "0   Action, Adventure, Drama     9.3  1,769,233  \n",
       "1     Drama, Fantasy, Horror     8.7    821,635  \n",
       "2    Drama, Horror, Thriller     8.2    853,072  \n",
       "3   Drama, Mystery, Thriller     7.6    256,113  \n",
       "4     Drama, Mystery, Sci-Fi     7.6    216,348  \n",
       "..                       ...     ...        ...  \n",
       "95            Drama, Fantasy     7.5     43,572  \n",
       "96  Adventure, Comedy, Drama     7.8     53,853  \n",
       "97     Crime, Drama, Mystery     8.1    161,105  \n",
       "98      Crime, Drama, Horror     7.2     34,082  \n",
       "99    Drama, Horror, Mystery     8.6    182,229  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_Series=pd.DataFrame([])\n",
    "TV_Series['Name']=Name\n",
    "TV_Series['Year_span']=Year_span\n",
    "TV_Series['Run_time']=Run_time\n",
    "TV_Series['Genres']=Genres\n",
    "TV_Series['Ratings']=Ratings\n",
    "TV_Series['Votes']=Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
